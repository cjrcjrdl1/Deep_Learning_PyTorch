합성곱 신경망 : 이미지 전체를 한 번에 계산하는 것이 아닌 이미지의 국소적 부분을 계산함으로써 시간과 자원을 절약하여 이미지의 세밀한 부분까지 분석할 수 있는 신경망

합성곱 신경망은 이미지나 영상 처리하는 데 유용

이미지 분석은 펼쳐서 각 픽셀에 가중치 곱하여 은닉층 전달
이렇게 펼치면 데이터의 공간적 구조를 무시하게 되는데 이를 방지하기 위해 도입된 것 -> 합성곱층

합성곱 신경망 구조
입력층 -> 합성곱층 -> 풀링층 -> 완전연결층 -> 출력층

합성곱층과 풀링층을 거치면서 입력 이미지의 주요 특성 벡터를 추출

그 후 추출된 주요 특성 벡터들은 완전연결층을 거치면서 1차원 벡터로 변환

마지막으로 출력층에서 소프트맥스 함수를 사용하면 최종결과 출력

합성곱의 신경망 구조에 대해 알아보자
입력층
이미지는 단순 1차원이 X
높이, 너비, 채널 값을 갖는 3차원 데이터
채널은 이미지가 그레이스케일(회색조 색상)이면 1 값을 가지며 컬러(RGB) 이면 3 값을 가짐

* 1 값을 가지는 이유는 단색, 3 값을 가지는 것은 R, G, B 각각 가지므로

이미지의 형태(shape)은 (height, width, channel)

합성곱층은 입력데이터에서 특성을 추출하는 역할을 수행

이 때 특성은 어떻게 추출?
입력 이미지가 들어왔을 때 이미지에 대한 특성을 감지하기 위해 커널이나 필터 사용
커널/필터는 이미지 모든 영역을 훑으며 특성을 추출
추출된 결과물 -> 특성 맵(feature map)
커널은 보통 3x3, 5x5 크기로 적용되는 것이 일반적이고, 스트라이드라는 지정된 간격에 따라 순차적 이동

입력이랑 필터랑 포개 놓고 대응되는 숫자끼리 곱한 후 모두 더한 값을 출력층에 입력
이후 입력이미지에 필터가 1만큼 이동하는 것을 반복
오른쪽 끝까지 돌았다면 아래로 한칸 내려가서 다시 진행 반복

예제 그림같은 경우는 원본 (6,6,1) 크기가 (4,4,1) 크기의 특성 맵으로 줄어들음(height, width, channel)

그레이 스케일에 대한 합성곱은 위와 같고 컬러 이미지의 합성곱을 알아보자

앞의 그레이스케일 이미지와 구분되는 것은
필터 채널이 3이라는 것과, RGB각각에 서로 다른 가중치로 합성곱을 적용한 후 결과를 더함
필터 채널이 3이라고 해서 필터 개수도 3개로 오해하기 쉬우나 실제로는 필터 개수가 한개라는 점에 주의



합성곱층을 요약하면 다음과 같음
입력 데이터 : W1 * H1 * D1(W1 : 가로, H1 : 세로, D1 : 채널 또는 깊이)
하이퍼파라미터
필터 개수 : K
필터 크기 : F
스트라이드 : S
패딩 : P
출력 데이터
W2 = (W1-F+2P)/S+1
H2 = (H1-F+2P)/S+1
D2 = K(필터 개수)

풀링층은 합성곱층과 유사하게 특성 맵의 차원을 다운 샘플링하여
연산량 감소, 주요한 특성 벡터를 추출하여 학습을 효과적으로 할 수 있게 함

여기서 다운샘플링이란? 이미지를 축소시키는 것 !!

풀링 연산에는 두가지 사용
최대 풀링 : 대상 영역에서 최댓값 추출
평균 풀링 : 대상 영역에서 평균을 반환

대부분 합성곱 신경망에선 최대 풀링이 사용된다.
평균 풀링은 각 커널 값을 평균화시켜 중요한 가중치를 갖는 값의 특징이 희미해질 수 있기 때문

최대풀링 연산 과정
4개의 값 중 가장 큰 값 선택해서 출력(그림보면서 설명)
평균풀링도 거의 똑같은데, 큰 값이 아닌 각 필터의 평균을 구하기만 하면 된다.

최대 풀링과 평균 풀링을 요약하면 다음과 같음(연산과정은 다르나 사용하는 파라미터는 동일)
입력 데이터 : W1*H1*D1
하이퍼파라미터
필터 크기 : F
스트라이드 : S
출력 데이터
W2 = (W1-F)/S+1
H2 = (H1-F)/S+1
D2 = D1

완전연결층
합성곱층과 풀링층을 거치며 차원이 축소된 특성 맵은 최종적으로 완전연결층에 도달
이 과정에서 이미지는 3차원 벡터에서 1차원 벡터로 펼쳐지게(flatten) 됨

출력층
출력층에서는 소프트맥스 함수 사용 -> 0~1 사이의 값으로 출력
이미지가 각 레이블에 속할 확률 값이 출력되며
이때 가장 높은 확률 값을 갖는 레이블이 최종 값으로 선정

합성곱은 이동하는 방향의 수와 출력 형태에 따라 1D, 2D, 3D로 분류할 수 있음

1D 합성곱
1D 합성곱은 필터가 시간을 축으로 좌우로만 이동할 수 있는 합성곱
입력(W)와 필터(k)에 대한 출력은 W가 됨
예를 들어 입력이 [1, 1, 1, 1, 1]이고 필터가 [0.25, 0.5, 0.25]라면,
출력은 [1, 1, 1, 1, 1]이 됨 -> 입력이 출력과 동일!
이는 그래프 곡선이 완화할 때 많이 사용(그림 5-19)

2D 합성곱
2D 합성곱은 필터가 방향 두개로 움직이는 형태(그림 5-20)
입력(W,H)과 필터(k,k)에 대한 출력은 (W,H)가 되며, 출력 형태는 2D 행렬이 됨(2차원 형태!)

3D 합성곱
3D 합성곱은 필터가 움직이는 방향이 세개 있음 (그림 5-21)
입력(W,H,L)에 대해 필터(k,k,d)를 적용하면 출력으로 (W,H,L)을 갖는 형태가 3D 합성곱
출력은 3D 형태(3차원)이며, 이때 d < L을 유지하는 것이 중요(필터 깊이가 입출력의 길이보다 커지면 안됨! 그림 보면 이해 쉬움)

3D 입력을 갖는 2D 합성곱(그림5-22를 보고 설명)
입력이 3D 형태임에도 출력 형태가 3D가 아닌 2D 행렬을 취하는 것이다.
이것은 필터에 대한 길이(L)가 입력 채널의 길이(L)와 같아야 하기 때문에 이와 같은 합성곱 형태가 만들어짐
즉, 입력(W,H,L)에 대한 필터(k,k,L)를 적용하면 출력은 (W,H)가 됨
필터는 결국 2D 형태로 출력되므로 두 방향으로 움직이며 2D 행렬이 된다.
이 예시로는 LeNet-5와 VGG가 있다.

1X1 합성곱(그림 5-23)
1x1 합성곱은 3D 형태로 입력
즉, 입력(W,H,L)에 필터(1,1,L)를 적용하면 출력은 (W,H) 가 됨
1x1 합성곱에서 채널 수를 조정해서 연산량이 감소되는 효과가 있으며 대표적으로 GoogLeNet이 있음

fashion_mnist 데이터셋을 이용해서 실습 코드로 실습을 완료했습니다.
그중 몇가지만 뽑아서 설명해보겠습니다.

np.random.randint(10) 0~10의 임의의 숫자 입력
np.random.randint(1,10) 1~9의 임의의 숫자 입력
np.random.rand(8) 0~1 사이의 정규표준분포 난수를 행렬(1x8)출력
[0.89,0.24~~~~~8개]
np.random.rand(4,2) 위의 정규표준분포 난수를 4*2 행렬로 출력
np.random.randn(8) 표준이 0이고, 표준편차가 1인 가우시안 정규분포 난수를 행렬(1x8) 출력
np.random.randn(4,2) 위의 가우시안 정규분포 난수를 4*2 행렬로 출력

torch.nn.Dropout(p) p만큼의 비율로 텐서의 값이 0이 되고, 0이 되지 않는 값들은 기존 값에 (1/(1-p)) 만큼 곱해져 커짐

파이토치에서 사용하는 view(뷰)는 넘파이의 reshape과 같은 역할로 텐서의 크기(shape)를 변경해주는 역할
ex)input_data.view(-1, 784)는 input_data를 (?, 784)의 크기로 변경하라는 의미

활성화 함수 지정시 두가지 방법 가능
F.relu() : forward() 함수에서 정의
nn.ReLU() : __init__() 함수에서 정의

이 둘의 차이는 간단히는 사용하는 위치가 다르다
그리고 nn.활성화함수는 input_channel과 output_channel을 사용해서 연산하므로
파라미터를 새로 정의할 필요가 없으나

nn.functional(F.~~)은 입력과 가중치 자체를 직접 넣어줘야 한다.
즉, 가중치를 전달해야 할 때마다 가중치 값을 새로 정의해야 함

BatchNorm2d는 학습 과정에서 각 배치 단위별로 데이터가 다양한 분포를 가지더라도 평균과 분산을 이용해 정규화하는 것을 의미 -> 정규화를 통해 가우시안 형태로 만듦(평균은 0, 표준편차는 1)

MaxPool2d는 이미지 크기를 축소시키는 용도로 사용

합성곱 신경망은 심층 신경망과 비교하여 정확도가 약간 높음
데이터가 많아지면 단순 심층 신경망으로는 정확한 특성 추출 및 분류가 불가능하므로
합성곱 신경망을 생성할 수 있도록 학습해야 함

전이학습
합성곱 신경망 기반의 딥러닝 모델을 제대로 훈련시키려면 많은 데이터가 필요하나
큰 데이터셋을 얻기 쉽지 않음(많은돈, 시간 필요)
이 어려움을 해결한 것이 전이 학습

전이학습이란 이미지넷처럼 아주 큰 데이터셋을 써서 훈련된 모델의 가중치를 가져와 우리가 해결하려는 과제에 맞게 보정해서 사용하는 것을 의미

이때 아주 큰 데이터셋을 사용하여 훈련된 모델을 사전 훈련된 모델(네트워크)이라 함


전이학습의 기법으로는 (그림 5-30)
특성 추출 기법 : 이미지넷 데이터셋으로 사전 훈련된 모델을 가져온 후 마지막에 완결연결층 부분만 새로 만듦
즉, 학습할 때는 마지막 완전연결층(이미지 카테고리를 결정하는 부분)만 학습하고 나머지 계층들은 학습되지 않도록 함
특성 추출은 이미지 분류를 위해 두가지로 분류

- 합성곱 층 : 합성곱층과 풀링층으로 구성
- 데이터 분류기(완전연결층) : 추출된 특성을 입력받아 최종적으로 이미지에 대한 클래스를 분류하는 부분

특성 추출 기법에서 사용하는 이미지 분류 모델 종류는 다음과 같음
Xception
Inception V3
ResNet50
VGG16
VGG19
MobileNet

특성 추출 기법 실습 코드에서 몇가지만 뽑아서 설명하겠습니다.

torchvision.transform은 이미지 데이터를 변환하여 모델(네트워크)의 입력으로 사용할 수 있게 변환해줌
Resize : 이미지의 크기 조정
RandomResizedCrop : 이미지를 랜덤한 크기 및 비율로 자름(말 그대로 임의로 잘라버리는 것으로 그림 5-32를 참고하기 바람 153페이지)

Resize와 RandomResizedCrop 모두 이미지를 자르는 데 사용하지만 용도가 다르다.

Resize가 합성곱층을 통과하기 위해 이미지 크기를 조정하는 전처리 과정이라면,
RandomResizedCrop은 데이터 확장 용도로 사용

RandomHorizontalFlip : 이미지를 랜덤하게 수평으로 뒤집음
ToTensor : 이미지 데이터를 텐서로 변환

!!!그리고 .next()가 아님 !!! 154p 참고
-> next(           ) 이렇게 해주어야 오류가 안남
서적 내용은 아마 이전버전이라 오류가 난 것 같음!!!

ResNet18
ResNet18은 50개의 계층으로 구성된 합성곱 신경망
입력 제약이 매우 크고, 충분한 메모리(RAM)가 없으면 학습속도 느릴 수 있다는 단점 있음

모델에 pretrained=True를 설정하면 사전 학습된 모델을 사용할 수 있다!

ResNet18의 합성곱층을 사용하되 파라미터에 대해서는 학습하지 않도록 고정하기 위해서는
requires_grad = False로 설정하면 합성곱층은 사용하지만 학습은 하지 않는다.
즉, 모델의 일부(합성곱층과 풀링)를 고정하고 나머지를 학습하고자 할 때 사용
-> 완전연결층(분류하는애)만 학습!!

208페이지
tensor.clone()은 기존 텐서의 내용을 복사한 텐서를 생성
tensor.detach()는 기존 텐서에서 기울기가 전파되지 않는 텐서
tensor.clone().detach()는 기존 텐서를 복사한 새로운 텐서를 생성하지만 기울기엔 영향 안줌

이전에 배웠던 계산 그래프를 사용하는 이유는 두가지!
국소적 계산이 가능하다 -> 그림 5-39(210페이지)에서 Z 값이 변경되었다면 X, Y 계산 결과를    
      그대로 유지한 채로 바뀐 Z의 연산이 필요한 F=A×Z만 계산하면 됨
역전파를 통한 미분 계산이 편리 : chain rule을 이용하여 빠르고 간편하게 미분을 계산할 수 있음

chain rule이란 무엇인가?
두 개 이상의 함수가 결합된 함수. 즉, 합성 함수의 미분법을 chain rule

clip()은 입력 값이 주어진 범위를 벗어날 때 입력 값을 특정 범위로 제한시키기 위해 사용
imagel.clip(0,1)은 image 데이터를 0과 1 사이의 값으로 제한한다는 의미

그래서 특성 추출 기법의 결과는 220페이지 참고
초록색은 정확히 예측한 것, 빨간색은 예측이 잘못된 것
훈련 데이터를 늘리고, 에포크 횟수도 늘리면 더 좋은 결과를 얻을 수 있음

미세 조정 기법
미세 조정 기법은 특성 추출 기법에서 더 나아가
사전 훈련된 모델과 합성곱층, 데이터 분류기(완전연결층)의 가중치를 업데이트하여 훈련시키는 방식

특성추출은 목표 특성을 잘 추출했다는 전제하에 좋은 성능을 낼 수 있다.
특성이 잘못 추출되었다면 미세 조정 기법으로 새로운 이미지 데이터를 사용하여
네트워크 가중치를 업데이트해서 특성을 다시 추출할 수 있다.

-> 즉, 사전 학습된 모델을 목적에 맞게 재학습시키거나 학습된 가중치의 일부를 재학습시키는 것

데이터셋이 크고 사전 훈련된 모델과 유사성이 작은 경우
-> 모델 전체를 재학습시킴(데이터 셋이 크기 때문에 재학습이 유리)

데이터셋이 크고 사전 훈련된 모델과 유사성이 큰 경우
-> 합성곱층의 뒷부분(완전연결층과 가까운 부분)과 데이터 분류기(완전연결층)를 학습시킴

데이터셋이 작고 사전 훈련된 모델과 유사성이 적을 경우
-> 합성곱층의 일부분과 데이터 분류기(완전연결층)를 학습시킴(단, 데이터가 적기 때문에 미세조정기법을 적용해도 효과가 없을수도 있음)

데이터셋이 작고 사전 훈련된 모델과 유사성이 큰 경우
-> 데이터 분류기(완전연결층)만 학습시킴 (데이터가 적기 때문에 많은 계층에 미세 조정 기법을 적용하면 과적합 발생할 수 있으므로 최종 데이터 분류기인 완전 연결층에 대해서만 미세 조정 기법 적용)

설명 가능한 CNN (그림 5-45 페이지 229)
설명 가능한 CNN은 딥러닝 처리 결과를 사람이 이해할 수 있는 방식으로 제시하는 기술
CNN은 블랙박스와 같아 내부에서 어떻게 동작하는지 설명하기 어려움
즉, CNN으로 얻은 결과는 신뢰하기 어렵다.
이를 해결하려면 CNN 처리 과정을 시각화해야 할 필요성 있음

설명 가능한 CNN으로
특성 맵 시각화가 있다.
특성 맵(feature map)은 입력 이미지 또는 다른 특성 맵처럼 필터를 입력에 적용한 결과
특정 입력 이미지에 대한 특성 맵을 시각화한다는 의미는 특성 맵에서
입력 특성을 감지하는 방법을 이해할 수 있도록 돕는것

(실습 중간에 나오는 로그 소프트맥스란 소프트 맥스에 log 값을 취한 연산
이를 사용하는 이유는 소프트맥스는 기울기 소멸 문제에 취약하기 때문)

이미지 크기를 변경할 경우 변형된 이미지의 픽셀을 추정해서 값을 할당해야 하는데
존재하지 않으면 새로운 픽셀 값을 매핑하거나 존재하는 픽셀들을 압축해서 새로운 값을 할당해야 한다.
이러한 상황을 피하고자 이미지 상에 존재하는 픽셀 데이터들에 대해 근사함수 f(x,y)를 적용해서
새로운 픽셀 값을 구하는 것이 보간법이다.
즉, 추정해야 하는 픽셀을 보간법을 이용하여 값을 할당

실습을 다 마치고 263페이지
이제 원래 입력 이미지 값에 대한 형태는 전혀 찾아볼 수 없다.
즉, 출력층에 가까울수록 원래 형태는 찾아볼 수 업속, 이미지 특징들만 전달되는 것을 확인할 수 있다.

-> 특성 맵 시각화란 직관적으로 뭘 위해서 하는거냐고 묻는다면?
-> CNN의 결과에 신뢰성을 확보하기 위함이다

그래프 합성곱 네트워크 (그림 5-50, 268페이지)
그래프 합성곱 네트워크는 그래프 데이터를 위한 신경망
그래프는 방향성이 있거나 없는 엣지로 연결된 노드들의 집합
-> 노드는 원소들을 의미하고, 엣지는 결합 방법(single, double, triple)을 의미

그래프 신경망(GNN) (그림 5-51, 272페이지)
그래프 신경망(GNN 간)은 그래프 그래프 구조에서 사용하는 신경망
그래프 데이터에 대한 표현은 다음과 같이 두단계로 이뤄짐

1단계 인접행렬
가장 왼쪽 그림과 같은 네트워크가 있을 때 노드 n개를 nxn 행렬로 표현
이렇게 생성된 인접 행렬 내의 값 A(ij)는 i와 j의 관련성 여부를 만족하는 값으로 채움
직관적인 이해!!!
-> 인접 행렬 과정은 컴퓨터가 이해하기 쉽게 그래프로 표현하는 과정

2단계 특성행렬
인접 행렬만으로는 특성 파악이 어렵기에 단위행렬을 적용
각 입력 데이터에서 이용할 특성을 선택
특성 행렬에서 각 행은 선택된 특성에 대해 각 노드가 갖는 의미이다
-> 그림으로 직관적으로 보면 인접행렬과 특성행렬의 차이는 (특성행렬)자기자신에 대한 값을 1로 해줌!!

즉, 특성 행렬 과정을 거쳐 그래프 특성 추출

그래프 합성곱 네트워크(GCN) (그림 5-52, 275 페이지)
그래프 합성곱 네트워크는 이미지에 대한 합성곱을 그래프 데이터로 확장한 알고리즘
리드아웃 : 특성 행렬을 하나의 벡터로 변환하는 함수
즉, 전체 노드의 특성벡터에 대해 평균을 구하고 그래프 전체를 표현하는 하나의 벡터를 생성!
GCN에서 가장 중요한 부분은 합성곱층
그래프 합성곱층을 이용한 그래프 형태의 데이터는 행렬 형태의 데이터로 변환되어
딥러닝 알고리즘에 적용할 수 있기 때문(기존 그래프 형태 데이터로 딥러닝 알고리즘 적용할 수 없음)

GCN은
SNS에서 관계 네트워크
학술 연구에서 인용네트워크
3D Mesh
에서 사용


















