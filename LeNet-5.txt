LeNet-5
합성곱 신경망 개념을 개발한 구조
합성곱과 다운 샘플링(풀링)을 반복적으로 거쳐 마지막에 완전연결층에서 분류를 수행

!!32x32 크기의 이미지에 합성곱층과 최대 풀링층이 쌍으로 두번 적용된 후 완전연결층을 거쳐 이미지가 분류되는 신경망

transforms.Compose : 이미지를 변형할 수 있는 방식들의 묶음
transforms.RandomResizedCrop : 입력 이미지를 주어진 크기로 조정한다. 또한 scale은 원래 이미지를 임의의 크기50%~100% 만큼 면적을 무작위로 자르겠다는 의미
RandomHorizontalFlip : 주어진 확률로 이미지를 수평 반전 즉 훈련 이미지 중 반은 위 아래 뒤집힌 상태로 두고 반은 그대로 사용
ToTensor : 효율적인 연산을 위해 torch.FloatTensor 배열로 바꾸어야 하는데 이때 픽셀 값의 범위는 [0.0, 1.0] 사이가 되고 차원의 순서도 (채널수 x 높이 x 너비) 로 바뀐다. 이러한 작업 수행
Normalize : 사전 훈련된 모델을 사용하기 위해서 각 채널별 평균과 표준편차에 맞는 정규화를 해주어야 한다.

돌아가는 구조
합성곱층 - 렐루 - 풀링 - 합성곱층 - 렐루 - 풀링 - 완전연결층 구조이다.


ReLU 활성화 함수에서 inplace의 의미는 연산에 대한 결과값을 새로운 변수에 저장하는 것이 아닌 기존 데이터를 대체하는 것을 의미
즉, 기존 값을 연산 결과값으로 대체함으로써 기존 값들을 무시하겠다는 의미이다.

VGGNet은 합성곱층의 파라미터 수를 줄이고 훈련 시간을 개선하려고 탄생하였다.

즉, 네트워크를 깊게 만드는 것이 성능에 어떤 영향을 미치는지 확인하고자 나온 것이 VGG

VGG 연구 팀은 깊이의 영향만 최대한 확인하고자 합성곱층에서 사용하는 필터/커널의 크기를 가장 작은 3x3으로 고정했다.

네트워크 계층의 총 개수에 따라 여러 유형의 VGGNet(VGG16, VGG19 등)이 있다.

마지막 16번째 계층을 제외하고는 모두 ReLU 활성화 함수가 적용된다.

VGG 모델은 사전 훈련된 모델로 이미 누군가가 대용량의 이미지 데이터로 학습을 시켰으며, 최상의 상태로 튜닝을 거쳐
모든 사람들이 사용할 수 있도록 공유한 사전 훈련된 모델

메서드에 _ 표시가 있다면(torch.clamp_()) 기존의 메모리 공간에 있는 값을 새로운 값으로 대체하겠다는 의미로 받아들이면 된다.

GoogLeNet
GoogLeNet 은 주어진 하드웨어 자원을 최대한 효율적으로 이용하면서 학습 능력은 극대화할 수 있는 깊고 넓은 신경망
깊고 넓은 신경망을 위해 인셉션 모듈을 추가했다.
인셉션 모듈에서는 특징을 추출하기 위해 1x1, 3x3, 5x5의 합성곱 연산을 각각 수행한다.
3x3 최대 풀링은 입력과 출력의 높이와 너비가 같아야 하므로 풀링 연산에서는 드물게 패딩을 추가해야 한다.
결과적으로 GoogLeNet에 적용된 해결 방법은 희소 연결이다.
빽빽하게 연결된 신경망 대신 관련성이 높은 노드끼리만 연결하는 방법을 희소연결이라 한다.
이것으로 연산량이 적어지며 과적합도 해결할 수 있다.

심층 신경망의 아키텍처에서 계층이 넓고(뉴런이 많고) 깊으면(계층이 많으면) 인식률은 좋아지지만, 과적합이나 기울기 소멸 문제를 비롯한 학습 시간 지연과 연산 속도 등의 문제가 있다.
특히 합성곱 신경망에서 이러한 문제들이 자주 나타나는데, GoogLeNet(혹은 인셉션이라 불림)으로 이러한 문제를 해결할수 있다고 생각하면 된다.

ResNet
ResNet 핵심은 깊어진 신경망을 효과적으로 학습하기 위한 방법으로 레지듀얼 개념을 고안한 것
일반적으로 신경망 깊이가 깊어질수록 딥러닝 성능은 좋아질 것 같지만, 실상은 그렇지 않다.
"Deep Residual Learning for Image Recognition" 논문에 따르면, 신경망은 깊이가 깊어질수록
성능이 좋아지다가 일정한 단계에 다다르면 오히려 성능이 나빠진다고 한다.
-> 즉, 네트워크 깊이가 깊다고 해서 무조건 성능이 좋아지지는 않는다는 것을 알 수 있다.
ResNet은 바로 이러한 문제를 해결하기 위해 레지듀얼 블록을 도입했다.
레지듀얼 블록은 기울기가 잘 전파될 수 있도록 일종의 숏컷을 만들어준다.
-> 숏컷을 두어 기울기 소멸 문제 방지

블록은 계층의 묶음이다. 엄밀히 말해서 합성곱층을 하나의 블록으로 묶은 것이다.
이렇게 묶인 계층들을 하나의 레지듀얼 블록이라고 한다. 그리고 레지듀얼 블럭을 여러개 쌓은 것이 ResNet이다.

하지만 이렇게 계층을 계속해서 쌓아 늘리면 파라미터 수가 문제가 된다.
계층이 깊어질수록 파라미터는 증가한다.
계층의 깊이가 깊어질수록 파라미터는 무제한으로 커질 것이다.
이러한 문제를 해결하기 위해 병목 블록이라는 것을 두었다.

병목 블록을 두었을 때 깊이가 깊어졌음에도 파라미터 수가 감소한 것을 볼 수 있다.
어떻게 가능한 것인가? 앞에선 분명 깊이가 깊어질수록 파라미터 수가 증가한다고 했다.
하지만 병목블록을 사용하면 파라미터 수가 감소하는 효과를 줄 수 있다.
합성곱층을 자세히 보면 ResNet34와는 다르게 ResNet50에서는 3x3 합성곱층 앞뒤로 1x1 합성곱층이 붙어 있는데,
1x1 합성곱층의 채널 수를 조절하면서 차원을 줄였다 늘리는 것이 가능하기 때문에
파라미터 수를 줄일 수 있었던 것이다. 그릭도 이 부분이 병목과 같다고 하여 병목 블록이라고 한다.


아이덴티티 매핑(혹은 숏컷, 스킵연결이라고도 함)은 + 기호 부분을 아이덴티티 매핑이라고 한다.
아이덴티티 매핑이란 입력 x가 어떤 함수를 통과하더라도 다시 x라는 형태로 출력되도록 한다.

또 다른 핵심 개념인 다운샘플은 특성 맵 크기를 줄이기 위한 것으로 풀링과 같은 역할을 한다고 이해하면 된다.

입력과 출력의 차원이 같은 것을 아이덴티티 블록이라고 하며, 입력 및 출력 차원이 동일하지 않고
입력의 차원을 출력에 맞추어 변경해야 하는 것을 프로젝션 숏컷 혹은 합성곱 블록이다.

정리하면 ResNet은 기본적으로 VGG19 구조를 뼈대로 하며, 거기에 합성곱층들을 추가해서 깊게 만든 후
숏컷들을 추가하는 것이 사실상 전부라고 생각하면 된다.

각 레지듀얼 분기에 있는 마지막 BN(Batch Nornalization)을 0으로 초기화해서
다음 레지듀얼 분기를 0에서 시작할 수 있도록 한다.
이 부분은 모델을 생성하고 학습시키는 것과 상관없지만,
BN을 0으로 초기화할 경우 모델 성능이 0.2~0.3% 정도 향상된다.

객체 인식은 이미지나 영상 내에 있는 객체를 식별하는 컴퓨터 비전 기술이다.

즉, 객체 인식이란 이미지나 영상 내에 있는 여러 객체에 대해 각 객체가 무엇인지 분류하는 문제와 그 객체 위치가 어디인지 박스로 나타내는 위치 검출 문제를 다루는 분야

따라서 객체 인식은 다으모가 같이 표현할 수 있다.
객체 인식 = 여러가지 객체에 대한 분류 + 객체의 위치 정보를 파악하는 위치 검출

딥러닝을 이용한 객체 인식 알고리즘은 크게 1단계 객체 인식과 2단계 객체 인식으로 나눌 수 있다.

1단계 객체 인식은 두 문제(분류와 위치 검출)를 동시에 행하는 방법이고, 2단계 객체 인식은 이 두 문제를 순차적으로 행하는 방법
따라서 1단계 객체 인식은 비교적 빠르지만 정확도가 낮고, 2단계 객체 인식은 비교적 느리지만 정확도가 높다.

2단계 객체 인식은 CNN을 처음으로 적용시킨 R-CNN 계열이 대표적이며, 1단계 객체 인식에는 YOLO 계열과 SSD 계열 등이 포함

객체 인식은 자율주행 자동차, CCTV, 무인점포 등 많은 곳에서 활용

여기서는 2단계 객체 인식 알고리즘에 대해 알아볼 것

R-CNN
예전의 객체 인식 알고리즘들은 슬라이딩 윈도우 방식, 즉 일정한 크기를 가지는 윈도우를 가지고
이미지의 모든 영역을 탐색하면서 객체를 검출해 내는 방식이었다.
하지만 알고리즘의 비효율성 때문에 많이 사용하지 않았으며, 현재는 선택적 탐색 알고리즘을 적용한 후보 영역을 많이 사용

R-CNN은 이미지 분류를 수행하는 CNN과 이미지에서 객체가 있을 만한 영역을 제안해 주는 후보 영역 알고리즘을 결합한 알고리즘

선택적 탐색
선택적 탐색은 객체 인식이나 검출을 위한 가능한 후보 영역(객체가 있을만한 위치 영역)을 알아내는 방법이다.
선택적 탐색은 분할 방식을 이용하여 시드를 선정하고, 그 시드에 대한 완전 탐색을 적용한다.

선택적 탐색은 다음 세 단계 과정을 거친다.
1. 초기 영역 생성 : 각각의 객체가 영역 한개에 할당될 수 있도록 많은 초기영역 생성
즉, 입력된 이미지를 영역 다수 개로 분할하는 과정

2. 작은 영역의 통합 : 1단계에서 영역 여러 개로 나눈 것들을 비슷한 영역으로 통합하는데, 이때 탐욕 알고리즘을 사용하여
비슷한 영역이 하나로 통합될 때까지 반복

3. 후보 영역 생성 : 2단계에서 통합된 이미지들을 기반으로 다음 그림과 같이 후보 영역(바운딩 박스)을 추출한다.


R-CNN은 성능이 뛰어나기는 하지만 다음과 같은 단점으로 크게 발전하지는 못함
1. 앞서 설명한 세단계의 복잡한 학습 과정
2. 긴 학습 시간과 대용량 저장 공간
3. 객체 검출 속도 문제

이러한 문제를 해결하기 위해 Fast R-CNN이 생겼음

공간 피라미드 풀링
기존 CNN 구조들은 모두 완전연결층을 위해 입력 이미지를 고정해야 했다.
그렇기 때문에 신경망을 통과시키려면 이미지를 고정된 크기로 자르거나(crop) 비율을 조정(warp)해야 했다.
하지만 이렇게 하면 물체의 일부분이 잘리거나 본래의 생김새와 달라지는 문제가 있다.
이러한 문제를 해결하고자 공간 피라미드 풀리을 도입했다.


즉, 공간 피라미드 풀링은 입력 이미지의 크기에 관계없이 합성곱층을 통과시키고, 완전연결층에 전달되기 전에
특성 맵들을 동일한 크기로 조절해주는 풀링층을 적용하는 기법이다.

입력 이미지의 크기를 조절하지 않고 합성곱층을 통과시키기 때문에 원본 이미지의 특징이 훼손되지 않는 특성 맵을 얻을 수 있다.
또한, 이미지 분류나 객체 인식 같은 여러 작업에 적용할 수 있다는 장점이 있다.

Fast R-CNN
R-CNN은 바운딩 박스마다 CNN을 돌리고, 분류를 위해 긴 학습 시간이 문제였다.
Fast R-CNN은 R-CNN의 속도 문제를 개선하려고 Rol 풀링을 도입했다.
즉, 선택적 탐색에서 찾은 바운딩 박스 정보가 CNN을 통과하면서 유지되도록 하고 최종 CNN 특성 맵은
풀링을 적용하여 완전연결층을 통과하도록 크기를 조정한다.
이렇게 하면 바운딩 박스마다 CNN을 돌리는 시간을 단축할 수 있다.

Rol풀링
Rol 풀링은 크기가 다른 특성 맵의 영역마다 스트라이드를 다르게 최대 풀링을 적용하여 결과값 크기를 동일하게 맞추는 방법

Faster R-CNN
Faster R-CNN은 더욱 빠른 객체 인식을 수행하기 위한 네트워크이다.
기존 Fast R-CNN 속도의 걸림돌이었던 후보 영역 생성을 CNN 내부 네트워크에서 진행할 수 있도록 설계했다.
즉, Faster R-CNN은 기존 Fast R-CNN에 후보 영역 추출 네트워크를 추가한 것이 핵심이라고 할 수 있다.
Faster R-CNN에서는 외부의 느린 선택적 탐색(CPU로 계싼) 대신 내부의 빠른 RPN(GPU로 계산)을 사용한다.

RPN은 마지막 합성곱층 다음에 위치하고, 그 뒤에 Fast R-CNN과 마찬가지로 Rol 풀링과 분류기, 바운딩 박스 회귀가 위치한다.

이미지 분할은 신경망을 훈련시켜 이미지를 픽셀 단위로 분할하는 것이다.

완전 합섭공 네트워크
완전연결층의 한계는 고정된 크기의 입력만 받아들이며 완전연결층을 거친 후에는 위치 정보가 사라진단느 것이다.
이러한 문제를 해결하기 위해 완전연결층을 1x1 합성곱으로 대체하는 것이 완전 합성곱 네트워크이다.

합성곱 & 역합성곱 네트워크
완전 합성곱 네트워크는 위치정보가 보존된다는 장점에도 다음과 같은 단점이 있음
여러 단계의 합성곱층과 풀링츨을 거치면서 해상도가 낮아진다.
낮아진 해상도를 복원하기 위해 업 샘플링 방식을 사용하기 때문에 이미지의 세부 정보를 잃어버리는 문제가 발생한다.
이러한 문제를 해결하기 위해 역합성곱 네트워크를 도입한 것

역합성곱은 CNN의 최종 출력 결과를 원래의 입력 이미지와 같은 크기로 만들고 싶을 때 사용
시멘틱 분할 등에 활용할 수 있으며, 역합성곱을 업 샘플링이라고도 한다.

U-Net
바이오 메디컬 이미지 분할을 위한 합성곱 신경망
속도가 빠르고 트레이드 오프에 빠지지 않는다는 특징이 있다.

PSPNet
시멘틱 분할 알고리즘이다.
이 역시 완전연결층의 한계를 극복하기 위해 피라미드 풀링 모듈을 추가했다.

DeepLabv3/DeepLabv3+
이 역시 완전연결층의 단점을 보완하기 위해 Atrous 합성곱을 사용하는 네트워크이다.
인코더와 디코저 구조를 가진다.




